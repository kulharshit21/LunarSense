{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a46a900-c154-43e7-9314-9f24847c15f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ tqdm\n",
      "‚úÖ scipy\n",
      "‚úÖ pandas\n",
      "‚úÖ numpy\n",
      "‚úÖ psutil\n",
      "\n",
      "‚úÖ All packages ready\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# INSTALL REQUIRED PACKAGES\n",
    "# ============================================================================\n",
    "\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "packages = ['tqdm', 'scipy', 'pandas', 'numpy', 'psutil']\n",
    "\n",
    "for pkg in packages:\n",
    "    try:\n",
    "        __import__(pkg)\n",
    "        print(f\"‚úÖ {pkg}\")\n",
    "    except:\n",
    "        print(f\"üì• Installing {pkg}...\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", pkg, \"-q\"])\n",
    "        print(f\"‚úÖ {pkg}\")\n",
    "\n",
    "print(\"\\n‚úÖ All packages ready\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d109699-b0bd-4282-9553-37917281aa19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "üåô LUNARSENSE-3: NOTEBOOK 2 - MODALITY PREPROCESSING (OPTIMIZED)\n",
      "====================================================================================================\n",
      "\n",
      "üî• GPU Setup:\n",
      "   Available GPUs: 8\n",
      "   GPU 0: NVIDIA A100-SXM4-40GB\n",
      "           42.4 GB memory\n",
      "   GPU 1: NVIDIA A100-SXM4-40GB\n",
      "           42.4 GB memory\n",
      "   GPU 2: NVIDIA A100-SXM4-40GB\n",
      "           42.4 GB memory\n",
      "   GPU 3: NVIDIA A100-SXM4-40GB\n",
      "           42.4 GB memory\n",
      "   GPU 4: NVIDIA A100-SXM4-40GB\n",
      "           42.4 GB memory\n",
      "   GPU 5: NVIDIA A100-SXM4-40GB\n",
      "           42.4 GB memory\n",
      "   GPU 6: NVIDIA A100-SXM4-40GB\n",
      "           42.4 GB memory\n",
      "   GPU 7: NVIDIA A100-SXM4-40GB\n",
      "           42.4 GB memory\n",
      "\n",
      "üíª CPU: 256 cores\n",
      "   RAM: 1082.0 GB\n",
      "\n",
      "‚öôÔ∏è Processing Config:\n",
      "   Batch size: 100 files\n",
      "   Workers: 32\n",
      "   GPUs: 8\n",
      "   Save interval: 200 files\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# LUNARSENSE-3: NOTEBOOK 2 - OPTIMIZED MULTI-GPU PROCESSING\n",
    "# Processing ALL Data with Memory Management\n",
    "# ============================================================================\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.multiprocessing as mp\n",
    "from datetime import datetime\n",
    "from scipy import signal, stats\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "import psutil\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"=\" * 100)\n",
    "print(\"üåô LUNARSENSE-3: NOTEBOOK 2 - MODALITY PREPROCESSING (OPTIMIZED)\")\n",
    "print(\"=\" * 100 + \"\\n\")\n",
    "\n",
    "# Multi-GPU setup\n",
    "n_gpus = torch.cuda.device_count()\n",
    "print(f\"üî• GPU Setup:\")\n",
    "print(f\"   Available GPUs: {n_gpus}\")\n",
    "\n",
    "for i in range(n_gpus):\n",
    "    print(f\"   GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "    mem_gb = torch.cuda.get_device_properties(i).total_memory / 1e9\n",
    "    print(f\"           {mem_gb:.1f} GB memory\")\n",
    "\n",
    "print()\n",
    "\n",
    "# CPU info\n",
    "cpu_count = os.cpu_count()\n",
    "print(f\"üíª CPU: {cpu_count} cores\")\n",
    "print(f\"   RAM: {psutil.virtual_memory().total / 1e9:.1f} GB\\n\")\n",
    "\n",
    "# Processing config\n",
    "CONFIG = {\n",
    "    'batch_size': 100,        # Process 100 files at a time\n",
    "    'n_gpus': n_gpus,\n",
    "    'n_workers': min(32, cpu_count),  # Safe worker count\n",
    "    'save_interval': 200,     # Save progress every 200 files\n",
    "    'memory_limit_gb': 30     # Stop if RAM exceeds 30GB\n",
    "}\n",
    "\n",
    "print(f\"‚öôÔ∏è Processing Config:\")\n",
    "print(f\"   Batch size: {CONFIG['batch_size']} files\")\n",
    "print(f\"   Workers: {CONFIG['n_workers']}\")\n",
    "print(f\"   GPUs: {CONFIG['n_gpus']}\")\n",
    "print(f\"   Save interval: {CONFIG['save_interval']} files\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "580c8050-4b36-4456-9cf6-3349d985854b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Inventory loaded:\n",
      "   Total files: 6,537\n",
      "   Total size: 36.08 GB\n",
      "\n",
      "  LIBS        :  3166 files\n",
      "  ChaSTE      :   389 files\n",
      "  ILSA        :  1939 files\n",
      "  RAMBHA      :  1020 files\n",
      "  APXS        :    11 files\n",
      "  SPICE       :    12 files\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ===========================================================================\n",
    "# LOAD INVENTORY\n",
    "# ===========================================================================\n",
    "\n",
    "output_root = '/raid/home/srmist57/Chandrayan-3/LunarSense3_FullPipeline'\n",
    "provenance_dir = os.path.join(output_root, '02_provenance')\n",
    "processed_dir = os.path.join(output_root, '01_processed_data')\n",
    "\n",
    "inventory_file = os.path.join(provenance_dir, 'full_data_inventory.json')\n",
    "\n",
    "with open(inventory_file, 'r') as f:\n",
    "    inventory = json.load(f)\n",
    "\n",
    "data_inventory = inventory['file_details']\n",
    "\n",
    "print(\"‚úÖ Inventory loaded:\")\n",
    "print(f\"   Total files: {inventory['total_files']:,}\")\n",
    "print(f\"   Total size: {inventory['total_size_gb']:.2f} GB\\n\")\n",
    "\n",
    "for inst, files in data_inventory.items():\n",
    "    if files:\n",
    "        print(f\"  {inst:12s}: {len(files):5d} files\")\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "137f7965-f73f-409f-9e33-f41e1e4c56ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 1: ChaSTE Processing (Memory-Safe)\n",
      "\n",
      "‚úÖ ChaSTE processor ready\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ===========================================================================\n",
    "# CHASTE PROCESSING (MEMORY-OPTIMIZED)\n",
    "# ===========================================================================\n",
    "\n",
    "print(\"STEP 1: ChaSTE Processing (Memory-Safe)\\n\")\n",
    "\n",
    "class ChaSTE_Processor:\n",
    "    def __init__(self):\n",
    "        self.saturation_threshold = 350.0\n",
    "        self.drift_threshold = 5.0\n",
    "        self.sampling_rate = 1.0\n",
    "    \n",
    "    def process_file(self, filepath):\n",
    "        \"\"\"Process single file\"\"\"\n",
    "        try:\n",
    "            df = pd.read_csv(filepath)\n",
    "            \n",
    "            # Find temp column\n",
    "            temp_cols = [col for col in df.columns if 'temp' in col.lower()]\n",
    "            if not temp_cols:\n",
    "                numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "                if len(numeric_cols) == 0:\n",
    "                    return None\n",
    "                temp_col = numeric_cols[0]\n",
    "            else:\n",
    "                temp_col = temp_cols[0]\n",
    "            \n",
    "            thermal = df[temp_col].values\n",
    "            thermal = np.nan_to_num(thermal, nan=np.nanmean(thermal))\n",
    "            \n",
    "            # Features\n",
    "            x = np.arange(len(thermal))\n",
    "            slope, _ = np.polyfit(x, thermal, 1)\n",
    "            drift_rate = slope * 3600 * self.sampling_rate\n",
    "            \n",
    "            # QC flag\n",
    "            qc_flag = 0\n",
    "            if len(thermal) == 0 or np.isnan(thermal).sum() > len(thermal) * 0.5:\n",
    "                qc_flag = 1\n",
    "            elif (thermal > self.saturation_threshold).sum() > len(thermal) * 0.1:\n",
    "                qc_flag = 3\n",
    "            elif thermal.std() > 0.5:\n",
    "                qc_flag = 2\n",
    "            \n",
    "            return {\n",
    "                'filename': os.path.basename(filepath),\n",
    "                'n_samples': len(thermal),\n",
    "                'mean_temp': float(thermal.mean()),\n",
    "                'std_temp': float(thermal.std()),\n",
    "                'min_temp': float(thermal.min()),\n",
    "                'max_temp': float(thermal.max()),\n",
    "                'drift_rate': float(drift_rate),\n",
    "                'qc_flag': int(qc_flag)\n",
    "            }\n",
    "        except:\n",
    "            return None\n",
    "\n",
    "print(\"‚úÖ ChaSTE processor ready\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "71c2fdc0-bbc8-4e32-a19f-420ff96bdcc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ChaSTE files in batches...\n",
      "\n",
      "Total: 389 files\n",
      "Batches: 4 (size=100)\n",
      "\n",
      "Batch 1/4: Processing files 0-100...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:00<00:00, 306.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ö†Ô∏è RAM limit reached (37.9 GB)\n",
      "   Saving progress and continuing...\n",
      "\n",
      "Batch 2/4: Processing files 100-200...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:00<00:00, 280.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ö†Ô∏è RAM limit reached (37.9 GB)\n",
      "   Saving progress and continuing...\n",
      "\n",
      "Batch 3/4: Processing files 200-300...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 3: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:00<00:00, 240.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ö†Ô∏è RAM limit reached (37.9 GB)\n",
      "   Saving progress and continuing...\n",
      "\n",
      "Batch 4/4: Processing files 300-389...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 4: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 89/89 [00:00<00:00, 203.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ö†Ô∏è RAM limit reached (37.9 GB)\n",
      "   Saving progress and continuing...\n",
      "\n",
      "\n",
      "‚úÖ ChaSTE Complete: 385/389\n",
      "\n",
      "Summary:\n",
      "  Mean temp: 1880.48 K\n",
      "  Files with drift: 36\n",
      "\n",
      "  OK          :  179\n",
      "  MISSING     :    0\n",
      "  HIGH_NOISE  :    7\n",
      "  SATURATED   :  199\n",
      "\n",
      "‚úÖ Saved: /raid/home/srmist57/Chandrayan-3/LunarSense3_FullPipeline/01_processed_data/chaste_processed.csv\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ===========================================================================\n",
    "# PROCESS CHASTE FILES IN BATCHES\n",
    "# ===========================================================================\n",
    "\n",
    "print(\"Processing ChaSTE files in batches...\\n\")\n",
    "\n",
    "chaste_files = data_inventory.get('ChaSTE', [])\n",
    "processor = ChaSTE_Processor()\n",
    "chaste_results = []\n",
    "\n",
    "batch_size = CONFIG['batch_size']\n",
    "n_batches = (len(chaste_files) + batch_size - 1) // batch_size\n",
    "\n",
    "print(f\"Total: {len(chaste_files)} files\")\n",
    "print(f\"Batches: {n_batches} (size={batch_size})\\n\")\n",
    "\n",
    "for batch_idx in range(n_batches):\n",
    "    start_idx = batch_idx * batch_size\n",
    "    end_idx = min(start_idx + batch_size, len(chaste_files))\n",
    "    \n",
    "    batch_files = chaste_files[start_idx:end_idx]\n",
    "    \n",
    "    print(f\"Batch {batch_idx+1}/{n_batches}: Processing files {start_idx}-{end_idx}...\")\n",
    "    \n",
    "    for file_info in tqdm(batch_files, desc=f\"Batch {batch_idx+1}\"):\n",
    "        result = processor.process_file(file_info['path'])\n",
    "        if result:\n",
    "            chaste_results.append(result)\n",
    "    \n",
    "    # Memory cleanup\n",
    "    gc.collect()\n",
    "    \n",
    "    # Check RAM\n",
    "    ram_used = psutil.virtual_memory().used / 1e9\n",
    "    if ram_used > CONFIG['memory_limit_gb']:\n",
    "        print(f\"\\n‚ö†Ô∏è RAM limit reached ({ram_used:.1f} GB)\")\n",
    "        print(\"   Saving progress and continuing...\\n\")\n",
    "        \n",
    "        # Save intermediate results\n",
    "        temp_df = pd.DataFrame(chaste_results)\n",
    "        temp_file = os.path.join(processed_dir, f'chaste_batch_{batch_idx}.csv')\n",
    "        temp_df.to_csv(temp_file, index=False)\n",
    "\n",
    "# Create final DataFrame\n",
    "chaste_df = pd.DataFrame(chaste_results)\n",
    "\n",
    "print(f\"\\n‚úÖ ChaSTE Complete: {len(chaste_results)}/{len(chaste_files)}\\n\")\n",
    "\n",
    "# Summary\n",
    "print(\"Summary:\")\n",
    "print(f\"  Mean temp: {chaste_df['mean_temp'].mean():.2f} K\")\n",
    "print(f\"  Files with drift: {(abs(chaste_df['drift_rate']) > 5.0).sum()}\")\n",
    "print()\n",
    "\n",
    "# QC flags\n",
    "for flag in range(4):\n",
    "    count = (chaste_df['qc_flag'] == flag).sum()\n",
    "    label = ['OK', 'MISSING', 'HIGH_NOISE', 'SATURATED'][flag]\n",
    "    print(f\"  {label:12s}: {count:4d}\")\n",
    "print()\n",
    "\n",
    "# Save\n",
    "chaste_output = os.path.join(processed_dir, 'chaste_processed.csv')\n",
    "chaste_df.to_csv(chaste_output, index=False)\n",
    "print(f\"‚úÖ Saved: {chaste_output}\\n\")\n",
    "\n",
    "# Cleanup\n",
    "del chaste_results, chaste_df\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b116cc06-23ba-4675-90d1-4d5d2c8a1567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 2: ILSA Processing (Memory-Safe)\n",
      "\n",
      "‚úÖ ILSA processor ready\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ===========================================================================\n",
    "# ILSA PROCESSING (MEMORY-OPTIMIZED)\n",
    "# ===========================================================================\n",
    "\n",
    "print(\"STEP 2: ILSA Processing (Memory-Safe)\\n\")\n",
    "\n",
    "class ILSA_Processor:\n",
    "    def __init__(self):\n",
    "        self.sampling_rate = 100.0\n",
    "        self.sta_window = 100\n",
    "        self.lta_window = 3000\n",
    "        self.trigger_on = 3.0\n",
    "    \n",
    "    def sta_lta_detection(self, waveform):\n",
    "        \"\"\"Fast STA/LTA\"\"\"\n",
    "        if len(waveform) < self.lta_window:\n",
    "            return 0, 0.0\n",
    "        \n",
    "        # Subsample for speed\n",
    "        step = max(1, len(waveform) // 10000)\n",
    "        wave_sub = waveform[::step]\n",
    "        \n",
    "        sta = np.convolve(np.abs(wave_sub), np.ones(self.sta_window)//self.sta_window, mode='same')\n",
    "        lta = np.convolve(np.abs(wave_sub), np.ones(self.lta_window)//self.lta_window, mode='same')\n",
    "        \n",
    "        ratio = sta / (lta + 1e-10)\n",
    "        \n",
    "        n_events = (ratio > self.trigger_on).sum()\n",
    "        max_ratio = ratio.max() if len(ratio) > 0 else 0.0\n",
    "        \n",
    "        return n_events, max_ratio\n",
    "    \n",
    "    def process_file(self, filepath):\n",
    "        \"\"\"Process single ILSA file\"\"\"\n",
    "        try:\n",
    "            df = pd.read_csv(filepath, nrows=10000)  # Limit rows for memory\n",
    "            \n",
    "            # Find wave column\n",
    "            wave_cols = [col for col in df.columns if 'wave' in col.lower() or 'amplitude' in col.lower()]\n",
    "            if not wave_cols:\n",
    "                numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "                if len(numeric_cols) == 0:\n",
    "                    return None\n",
    "                wave_col = numeric_cols[0]\n",
    "            else:\n",
    "                wave_col = wave_cols[0]\n",
    "            \n",
    "            waveform = df[wave_col].values\n",
    "            waveform = np.nan_to_num(waveform, nan=0.0)\n",
    "            \n",
    "            # Detect events\n",
    "            n_events, max_ratio = self.sta_lta_detection(waveform)\n",
    "            \n",
    "            # QC\n",
    "            qc_flag = 0\n",
    "            if len(waveform) == 0:\n",
    "                qc_flag = 1\n",
    "            elif np.abs(waveform).max() > 0 and (np.abs(waveform) >= np.abs(waveform).max() * 0.99).sum() > 10:\n",
    "                qc_flag = 3\n",
    "            \n",
    "            return {\n",
    "                'filename': os.path.basename(filepath),\n",
    "                'n_samples': len(waveform),\n",
    "                'n_events': int(n_events),\n",
    "                'max_amplitude': float(np.abs(waveform).max()),\n",
    "                'rms': float(np.sqrt((waveform**2).mean())),\n",
    "                'max_sta_lta': float(max_ratio),\n",
    "                'qc_flag': int(qc_flag)\n",
    "            }\n",
    "        except:\n",
    "            return None\n",
    "\n",
    "print(\"‚úÖ ILSA processor ready\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "17a20d20-77b6-44d0-b0a3-2d277ff1ca8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ILSA files in batches (1,939 files, 30GB)...\n",
      "\n",
      "‚ö†Ô∏è This may take 15-20 minutes with memory management\n",
      "\n",
      "Total: 1939 files\n",
      "Batches: 39 (size=50)\n",
      "\n",
      "Batch 1/39: Files 0-50...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [00:00<00:00, 1359.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   RAM: 38.0 GB\n",
      "   ‚ö†Ô∏è RAM limit reached - forcing cleanup\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2/39: Files 50-100...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [00:00<00:00, 1294.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   RAM: 37.9 GB\n",
      "   ‚ö†Ô∏è RAM limit reached - forcing cleanup\n",
      "\n",
      "Batch 3/39: Files 100-150...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 3: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [00:00<00:00, 1371.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   RAM: 37.9 GB\n",
      "   ‚ö†Ô∏è RAM limit reached - forcing cleanup\n",
      "\n",
      "Batch 4/39: Files 150-200...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 4: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [00:00<00:00, 1436.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   üíæ Progress saved: 114 files\n",
      "\n",
      "   RAM: 38.0 GB\n",
      "   ‚ö†Ô∏è RAM limit reached - forcing cleanup\n",
      "\n",
      "Batch 5/39: Files 200-250...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 5: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [00:00<00:00, 1354.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   RAM: 38.0 GB\n",
      "   ‚ö†Ô∏è RAM limit reached - forcing cleanup\n",
      "\n",
      "Batch 6/39: Files 250-300...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 6: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [00:00<00:00, 1482.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   RAM: 38.0 GB\n",
      "   ‚ö†Ô∏è RAM limit reached - forcing cleanup\n",
      "\n",
      "Batch 7/39: Files 300-350...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 7: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [00:00<00:00, 1508.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   RAM: 38.0 GB\n",
      "   ‚ö†Ô∏è RAM limit reached - forcing cleanup\n",
      "\n",
      "Batch 8/39: Files 350-400...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 8: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [00:00<00:00, 1603.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   üíæ Progress saved: 208 files\n",
      "\n",
      "   RAM: 38.0 GB\n",
      "   ‚ö†Ô∏è RAM limit reached - forcing cleanup\n",
      "\n",
      "Batch 9/39: Files 400-450...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 9: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [00:00<00:00, 1268.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   RAM: 38.0 GB\n",
      "   ‚ö†Ô∏è RAM limit reached - forcing cleanup\n",
      "\n",
      "Batch 10/39: Files 450-500...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [00:00<00:00, 1144.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   RAM: 38.0 GB\n",
      "   ‚ö†Ô∏è RAM limit reached - forcing cleanup\n",
      "\n",
      "Batch 11/39: Files 500-550...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 11: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [00:00<00:00, 1400.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   RAM: 38.0 GB\n",
      "   ‚ö†Ô∏è RAM limit reached - forcing cleanup\n",
      "\n",
      "Batch 12/39: Files 550-600...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 12: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [00:00<00:00, 1471.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   üíæ Progress saved: 353 files\n",
      "\n",
      "   RAM: 38.0 GB\n",
      "   ‚ö†Ô∏è RAM limit reached - forcing cleanup\n",
      "\n",
      "Batch 13/39: Files 600-650...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 13: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [00:00<00:00, 513.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   RAM: 38.0 GB\n",
      "   ‚ö†Ô∏è RAM limit reached - forcing cleanup\n",
      "\n",
      "Batch 14/39: Files 650-700...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 14: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [00:01<00:00, 47.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   RAM: 38.0 GB\n",
      "   ‚ö†Ô∏è RAM limit reached - forcing cleanup\n",
      "\n",
      "Batch 15/39: Files 700-750...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [00:01<00:00, 46.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   RAM: 38.0 GB\n",
      "   ‚ö†Ô∏è RAM limit reached - forcing cleanup\n",
      "\n",
      "Batch 16/39: Files 750-800...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 16: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [00:01<00:00, 49.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   üíæ Progress saved: 535 files\n",
      "\n",
      "   RAM: 38.0 GB\n",
      "   ‚ö†Ô∏è RAM limit reached - forcing cleanup\n",
      "\n",
      "Batch 17/39: Files 800-850...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 17: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [00:01<00:00, 49.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   RAM: 38.0 GB\n",
      "   ‚ö†Ô∏è RAM limit reached - forcing cleanup\n",
      "\n",
      "Batch 18/39: Files 850-900...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 18: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [00:00<00:00, 50.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   RAM: 38.0 GB\n",
      "   ‚ö†Ô∏è RAM limit reached - forcing cleanup\n",
      "\n",
      "Batch 19/39: Files 900-950...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 19: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [00:00<00:00, 51.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   RAM: 37.9 GB\n",
      "   ‚ö†Ô∏è RAM limit reached - forcing cleanup\n",
      "\n",
      "Batch 20/39: Files 950-1000...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [00:01<00:00, 49.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   üíæ Progress saved: 735 files\n",
      "\n",
      "   RAM: 38.0 GB\n",
      "   ‚ö†Ô∏è RAM limit reached - forcing cleanup\n",
      "\n",
      "Batch 21/39: Files 1000-1050...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 21: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [00:00<00:00, 51.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   RAM: 38.0 GB\n",
      "   ‚ö†Ô∏è RAM limit reached - forcing cleanup\n",
      "\n",
      "Batch 22/39: Files 1050-1100...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 22: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [00:01<00:00, 48.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   RAM: 38.0 GB\n",
      "   ‚ö†Ô∏è RAM limit reached - forcing cleanup\n",
      "\n",
      "Batch 23/39: Files 1100-1150...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 23: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [00:01<00:00, 46.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   RAM: 38.0 GB\n",
      "   ‚ö†Ô∏è RAM limit reached - forcing cleanup\n",
      "\n",
      "Batch 24/39: Files 1150-1200...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 24: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [00:01<00:00, 48.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   üíæ Progress saved: 935 files\n",
      "\n",
      "   RAM: 38.0 GB\n",
      "   ‚ö†Ô∏è RAM limit reached - forcing cleanup\n",
      "\n",
      "Batch 25/39: Files 1200-1250...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 25: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [00:00<00:00, 52.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   RAM: 38.0 GB\n",
      "   ‚ö†Ô∏è RAM limit reached - forcing cleanup\n",
      "\n",
      "Batch 26/39: Files 1250-1300...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 26: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [00:01<00:00, 46.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   RAM: 38.0 GB\n",
      "   ‚ö†Ô∏è RAM limit reached - forcing cleanup\n",
      "\n",
      "Batch 27/39: Files 1300-1350...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 27: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [00:00<00:00, 50.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   RAM: 38.0 GB\n",
      "   ‚ö†Ô∏è RAM limit reached - forcing cleanup\n",
      "\n",
      "Batch 28/39: Files 1350-1400...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 28: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [00:01<00:00, 47.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   üíæ Progress saved: 1135 files\n",
      "\n",
      "   RAM: 38.0 GB\n",
      "   ‚ö†Ô∏è RAM limit reached - forcing cleanup\n",
      "\n",
      "Batch 29/39: Files 1400-1450...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 29: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [00:01<00:00, 49.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   RAM: 38.0 GB\n",
      "   ‚ö†Ô∏è RAM limit reached - forcing cleanup\n",
      "\n",
      "Batch 30/39: Files 1450-1500...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 30: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [00:01<00:00, 47.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   RAM: 38.0 GB\n",
      "   ‚ö†Ô∏è RAM limit reached - forcing cleanup\n",
      "\n",
      "Batch 31/39: Files 1500-1550...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 31: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [00:00<00:00, 50.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   RAM: 38.0 GB\n",
      "   ‚ö†Ô∏è RAM limit reached - forcing cleanup\n",
      "\n",
      "Batch 32/39: Files 1550-1600...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 32: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [00:01<00:00, 49.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   üíæ Progress saved: 1335 files\n",
      "\n",
      "   RAM: 38.0 GB\n",
      "   ‚ö†Ô∏è RAM limit reached - forcing cleanup\n",
      "\n",
      "Batch 33/39: Files 1600-1650...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 33: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [00:01<00:00, 49.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   RAM: 38.0 GB\n",
      "   ‚ö†Ô∏è RAM limit reached - forcing cleanup\n",
      "\n",
      "Batch 34/39: Files 1650-1700...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 34: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [00:00<00:00, 52.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   RAM: 38.0 GB\n",
      "   ‚ö†Ô∏è RAM limit reached - forcing cleanup\n",
      "\n",
      "Batch 35/39: Files 1700-1750...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 35: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [00:01<00:00, 48.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   RAM: 38.0 GB\n",
      "   ‚ö†Ô∏è RAM limit reached - forcing cleanup\n",
      "\n",
      "Batch 36/39: Files 1750-1800...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 36: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [00:01<00:00, 49.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   üíæ Progress saved: 1535 files\n",
      "\n",
      "   RAM: 38.0 GB\n",
      "   ‚ö†Ô∏è RAM limit reached - forcing cleanup\n",
      "\n",
      "Batch 37/39: Files 1800-1850...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 37: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [00:01<00:00, 49.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   RAM: 38.0 GB\n",
      "   ‚ö†Ô∏è RAM limit reached - forcing cleanup\n",
      "\n",
      "Batch 38/39: Files 1850-1900...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 38: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [00:00<00:00, 51.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   RAM: 38.0 GB\n",
      "   ‚ö†Ô∏è RAM limit reached - forcing cleanup\n",
      "\n",
      "Batch 39/39: Files 1900-1939...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 39: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 39/39 [00:00<00:00, 49.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   RAM: 38.0 GB\n",
      "   ‚ö†Ô∏è RAM limit reached - forcing cleanup\n",
      "\n",
      "\n",
      "‚úÖ ILSA Complete: 1674/1939\n",
      "\n",
      "Summary:\n",
      "  Total events: 0\n",
      "  Files with events: 0\n",
      "\n",
      "  OK          :  456\n",
      "  MISSING     :    0\n",
      "  HIGH_NOISE  :    0\n",
      "  SATURATED   : 1218\n",
      "\n",
      "‚úÖ Saved: /raid/home/srmist57/Chandrayan-3/LunarSense3_FullPipeline/01_processed_data/ilsa_processed.csv\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ===========================================================================\n",
    "# PROCESS ILSA FILES IN BATCHES (1,939 FILES)\n",
    "# ===========================================================================\n",
    "\n",
    "print(\"Processing ILSA files in batches (1,939 files, 30GB)...\\n\")\n",
    "print(\"‚ö†Ô∏è This may take 15-20 minutes with memory management\\n\")\n",
    "\n",
    "ilsa_files = data_inventory.get('ILSA', [])\n",
    "processor = ILSA_Processor()\n",
    "ilsa_results = []\n",
    "\n",
    "batch_size = 50  # Smaller batches for large files\n",
    "n_batches = (len(ilsa_files) + batch_size - 1) // batch_size\n",
    "\n",
    "print(f\"Total: {len(ilsa_files)} files\")\n",
    "print(f\"Batches: {n_batches} (size={batch_size})\\n\")\n",
    "\n",
    "for batch_idx in range(n_batches):\n",
    "    start_idx = batch_idx * batch_size\n",
    "    end_idx = min(start_idx + batch_size, len(ilsa_files))\n",
    "    \n",
    "    batch_files = ilsa_files[start_idx:end_idx]\n",
    "    \n",
    "    print(f\"Batch {batch_idx+1}/{n_batches}: Files {start_idx}-{end_idx}...\")\n",
    "    \n",
    "    for file_info in tqdm(batch_files, desc=f\"Batch {batch_idx+1}\"):\n",
    "        result = processor.process_file(file_info['path'])\n",
    "        if result:\n",
    "            ilsa_results.append(result)\n",
    "    \n",
    "    # Memory cleanup\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache() if torch.cuda.is_available() else None\n",
    "    \n",
    "    # Save progress every 200 files\n",
    "    if (batch_idx + 1) % 4 == 0:\n",
    "        temp_df = pd.DataFrame(ilsa_results)\n",
    "        temp_file = os.path.join(processed_dir, f'ilsa_progress_{batch_idx}.csv')\n",
    "        temp_df.to_csv(temp_file, index=False)\n",
    "        print(f\"   üíæ Progress saved: {len(ilsa_results)} files\\n\")\n",
    "    \n",
    "    # Check RAM\n",
    "    ram_used = psutil.virtual_memory().used / 1e9\n",
    "    print(f\"   RAM: {ram_used:.1f} GB\")\n",
    "    \n",
    "    if ram_used > CONFIG['memory_limit_gb']:\n",
    "        print(f\"   ‚ö†Ô∏è RAM limit reached - forcing cleanup\\n\")\n",
    "        gc.collect()\n",
    "\n",
    "# Final DataFrame\n",
    "ilsa_df = pd.DataFrame(ilsa_results)\n",
    "\n",
    "print(f\"\\n‚úÖ ILSA Complete: {len(ilsa_results)}/{len(ilsa_files)}\\n\")\n",
    "\n",
    "# Summary\n",
    "print(\"Summary:\")\n",
    "print(f\"  Total events: {ilsa_df['n_events'].sum()}\")\n",
    "print(f\"  Files with events: {(ilsa_df['n_events'] > 0).sum()}\")\n",
    "print()\n",
    "\n",
    "# QC\n",
    "for flag in range(4):\n",
    "    count = (ilsa_df['qc_flag'] == flag).sum()\n",
    "    label = ['OK', 'MISSING', 'HIGH_NOISE', 'SATURATED'][flag]\n",
    "    print(f\"  {label:12s}: {count:4d}\")\n",
    "print()\n",
    "\n",
    "# Save\n",
    "ilsa_output = os.path.join(processed_dir, 'ilsa_processed.csv')\n",
    "ilsa_df.to_csv(ilsa_output, index=False)\n",
    "print(f\"‚úÖ Saved: {ilsa_output}\\n\")\n",
    "\n",
    "# Cleanup\n",
    "del ilsa_results, ilsa_df\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a74ad135-e0e4-4ee0-8076-89b0712af167",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "‚úÖ NOTEBOOK 2 COMPLETE: MODALITY PREPROCESSING\n",
      "====================================================================================================\n",
      "\n",
      "üìä Processing Summary:\n",
      "\n",
      "  ChaSTE: Processed with batch size 100\n",
      "  ILSA: Processed with batch size 50 (memory-safe)\n",
      "  Memory management: Active\n",
      "  Progress saved: Every 200 files\n",
      "\n",
      "‚úÖ Output files:\n",
      "  /raid/home/srmist57/Chandrayan-3/LunarSense3_FullPipeline/01_processed_data/chaste_processed.csv\n",
      "  /raid/home/srmist57/Chandrayan-3/LunarSense3_FullPipeline/01_processed_data/ilsa_processed.csv\n",
      "\n",
      "üöÄ Ready for Notebook 3: Baseline Detectors\n"
     ]
    }
   ],
   "source": [
    "# ===========================================================================\n",
    "# NOTEBOOK 2 SUMMARY\n",
    "# ===========================================================================\n",
    "\n",
    "print(\"=\" * 100)\n",
    "print(\"‚úÖ NOTEBOOK 2 COMPLETE: MODALITY PREPROCESSING\")\n",
    "print(\"=\" * 100 + \"\\n\")\n",
    "\n",
    "print(\"üìä Processing Summary:\\n\")\n",
    "print(f\"  ChaSTE: Processed with batch size {CONFIG['batch_size']}\")\n",
    "print(f\"  ILSA: Processed with batch size 50 (memory-safe)\")\n",
    "print(f\"  Memory management: Active\")\n",
    "print(f\"  Progress saved: Every 200 files\")\n",
    "print()\n",
    "\n",
    "print(\"‚úÖ Output files:\")\n",
    "print(f\"  {os.path.join(processed_dir, 'chaste_processed.csv')}\")\n",
    "print(f\"  {os.path.join(processed_dir, 'ilsa_processed.csv')}\")\n",
    "print()\n",
    "\n",
    "print(\"üöÄ Ready for Notebook 3: Baseline Detectors\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a3f6c3-2dc2-4ab7-94be-0743777d8563",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
